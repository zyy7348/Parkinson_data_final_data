---
title: "Homework 7"
author: "Yeyi Zhang"
date: "11/26/2017"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(modelr)
```

## Problem 1  

Loads the `iris` dataset from the `tidyverse` package and introduces some missing values in each column. 

```{r echo = FALSE}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

Let's fill in those missing values.
First, write a function that replaces missing values. Then, apply this function to the columns of `iris_with_missing` using a map statement

```{r}
fill_miss = function(x) {
  
  if (is.numeric(x)) {
    replace(x, is.na(x), mean(x, na.rm = TRUE))
  } else {
    replace(x, is.na(x), "virginica")
  }
}

map_df(iris_with_missing, fill_miss)
```

Edit the function so that different summaries can be used for numeric variables. Apply this function to the columns of `iris_with_missing` using a map statement, first using mean and then using median.

```{r}
summary_miss = function(x, summ_func) {
  
  if (is.numeric(x)) {
    replace(x, is.na(x), summ_func(x, na.rm = TRUE))
  } else {
    replace(x, is.na(x), "virginica")
  }
}

map_df(iris_with_missing, ~summary_miss(.x, mean))
map_df(iris_with_missing, ~summary_miss(.x, median))

```

## Problem 2  

Load and tidy the data as needed for analysis. Nest columns within boro and describe the resulting data frame.

```{r message = FALSE, warning = FALSE}
airbnb_data = read_csv("../data/nyc_airbnb.zip") %>%
  clean_names() %>%
  mutate(rating = review_scores_location / 2) %>%
  select(boro = neighbourhood_group, rating, price, room_type) %>%
  filter(!is.na(rating)) 

airbnb_nest = airbnb_data %>% 
  nest(rating:room_type)
```

Airbnb data is now separated into five boro-specific data frames, each of which is the data “observation” for the respective boro. What in the data frame is eactly what we had before.
The resulting data frame contains five rows and two columns, the first column `boro`is a character column and the second column `data` is a list column.


Fit models for rental price as an outcome using rating and room type as predictors. 

```{r}
lm_multi = function(df) {
  lm(price ~ rating + room_type, data = df)
}
```

Extract the results of your modeling and unnest the result. Present the results of your analysis, using text, tables, and figures as appropriate.

```{r}
airbnb_nest %>%
  mutate(models = map(data, lm_multi),
         results = map(models, broom::tidy)) %>% 
  select(-data, -models) %>% 
  unnest() %>% 
  select(-std.error, -statistic) %>%
  knitr::kable(digits = 3)
```

## Problem 3

First set the following design elements:

* Fix n=30
* Fix xi1 and xi2 as draws from independent standard normal distributions
* Fix beta0=1 and beta1=1.
* Fix σ^2=50

Next, set beta2=0. Generate 10000 datasets from the model:
yi = β0 + β1xi1 + β2xi2 + ϵi,     with ϵi∼N[0,σ2]. 

For each dataset, save 'beta2_hat' and the p-value arising from a test of H:β2=0 using α=0.05.

```{r}
set.seed(10)

sim_regression = function(beta2) {
  
  sim_data = tibble(
    xi1 = rnorm(30, mean = 0, sd = 1),
    xi2 = rnorm(30, mean = 0, sd = 1),
    y = 1 + 1 * xi1 + beta2 * xi2 + rnorm(30, 0, sqrt(50))
  )
  
  ls_fit = lm(y ~ xi1 + xi2, data = sim_data)
  
  tibble(
    beta2,
    beta2_hat = coef(ls_fit)[3],
    p_value = broom::tidy(ls_fit)$p.value[3]
  )
}
```

```{r eval = FALSE}
sim_results = rerun(10000, sim_regression(0)) %>% 
  bind_rows()
```

Repeat the above for β2={1,2,3,4,5,6}, and complete the following:

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of β2 on the x axis. Describe the association between effect size and power.

```{r}
set.seed(10)
beta2 = c(1:6)
multi_sim_results = rerun(10000, map_df(beta2, sim_regression)) %>% 
  bind_rows()
```

```{r}
multi_sim_results %>% 
  group_by(beta2) %>% 
  filter(p_value < 0.05) %>% 
  count() %>% 
  mutate(power = n/10000) %>% 
  ggplot(aes(x = beta2, y = power)) + 
  geom_point() + 
  stat_smooth(method = "lm",se = FALSE) +
    labs(title = "Association between power and effect size")
```

As the plot shows that there is a positive linear association between the effect size of beta2 and the power of the test.

Make a plot showing the average estimate of 'beta2_hat' on the y axis and the true value of β2 on the x axis. 

```{r}
multi_sim_results %>% 
  group_by(beta2) %>% 
  summarize(emp_mean = mean(beta2_hat)) %>% 
  ggplot(aes(x = beta2, y = emp_mean)) + 
  geom_point() + 
  stat_smooth(method = "lm") +
  labs(title = "Relationship between average estimate of 'beta2_hat' and true value of beta2",
       x = "Beta2",
       y = "Average estimate of beta2_hat")
```

Make a second plot (or overlay on the first) the average estimate of 'beta2_hat' in tests for which the null is rejected on the y axis and the true value of β2 on the x axis. 
* Is the sample average of 'beta2_hat' across tests for which the null is rejected approximately equal to the true value of β2? Why or why not?

```{r}
multi_sim_results %>% 
  group_by(beta2) %>% 
  filter(p_value < 0.05) %>% 
  summarize(emp_mean = mean(beta2_hat)) %>% 
  ggplot(aes(x = beta2, y = emp_mean)) + 
  geom_point() + 
  geom_abline(slope = 1, color = "red") +
  stat_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between average estimate of beta2_hat(rejecting H0) and true value of beta2",
       x = "Beta2",
       y = "Average estimate of beta2_hat (rejecting H0)")
```

For small effect size, the sample average of beta2_hat (null is rejected) does not approximate the true value of β2. However,
for larger effect size, the sample average of beta2_hat (null is rejected) does approximately the true value of β2. (red line as a reference, y=x)

As a result, when the true value of β2 is larger, we can make a better estimate of β2, as showed in `Association between power and effect size` figure that when the effect size increases, the power increases. 

## Problem 4

In this problem we’ll revisit the simulation design below.

```{r}
set.seed(1)

n_samp = 25

sim_df_const = tibble(
  x = rnorm(n_samp, 1, 1),
  error = rnorm(n_samp, 0, 1),
  y = 2 + 3 * x + error
)
```

Using the bootstrap, produce an empirical distribution for θ_hat; illustrate this distribution graphically.

```{r warning = FALSE, message = FALSE}
set.seed(1)
boot_straps = 
  sim_df_const %>% 
  bootstrap(n = 1000) %>% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x) ),
         results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest() %>% 
  select(.id, term, estimate) %>% 
  group_by(.id) %>% 
  spread(key = term, value = estimate) %>% 
  mutate(theta_hat = log(`(Intercept)` / x))

ggplot(boot_straps, aes(x = theta_hat)) + 
  geom_histogram(fill = "green", alpha = 0.5) +
  labs(title = "Distribution of theta hat (n = 50)",
    x = "theta hat",
    y = "density")
```

Increase the size of the simulated dataset to 50 and repeat the bootstrap procedure above. Increase again to 250 and repeat. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
set.seed(1)

n_samp = 50

tibble(
  x = rnorm(n_samp, 1, 1),
  error = rnorm(n_samp, 0, 1),
  y = 2 + 3 * x + error
) %>% 
  bootstrap(n = 1000) %>% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x) ),
         results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest() %>% 
  select(.id, term, estimate) %>% 
  group_by(.id) %>% 
  spread(key = term, value = estimate) %>% 
  mutate(theta_hat = log(`(Intercept)` / x)) %>% 
  ggplot(aes(x = theta_hat)) + 
  geom_histogram(fill = "blue", alpha = 0.5) +
  labs(title = "Distribution of theta hat (n = 25)",
    x = "theta hat")

```

```{r echo = FALSE, warning = FALSE, message = FALSE}
set.seed(1)

n_samp = 250

tibble(
  x = rnorm(n_samp, 1, 1),
  error = rnorm(n_samp, 0, 1),
  y = 2 + 3 * x + error
) %>% 
  bootstrap(n = 1000) %>% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x) ),
         results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest() %>% 
  select(.id, term, estimate) %>% 
  group_by(.id) %>% 
  spread(key = term, value = estimate) %>% 
  mutate(theta_hat = log(`(Intercept)` / x)) %>% 
  ggplot(aes(x = theta_hat)) + 
  geom_histogram(fill = "red", alpha = 0.5) +
  labs(title = "Distribution of theta hat (n = 250)",
    x = "theta hat")
```

According to the figures, the distribution of theta hat becomes more normally distributed as the sample size increases. In other words, when the sample size becomes larger, the mean of `theta_hat` becomes closer to the true value, which means that when sample sizes increase, we would get better estimation of our parameters. 